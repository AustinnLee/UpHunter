import time
import urllib.parse
import pandas as pd
from src.fetchers.stealth_browser import StealthBrowserFetcher
from src.parsers.upwork import UpworkParser
from src.storage.postgres import PostgresStorage
from src.database import SessionLocal
from src.core.logger import setup_logger
from src.models import UpworkJob

logger = setup_logger("Job.UpHunter")


def run():
    logger.info("ğŸ¹ å¯åŠ¨ UpHunter ä»»åŠ¡ (æ‰¹é‡ç¨³å¥ç‰ˆ)...")

    keywords = [
        "Data Engineering",
        "Streamlit",
        "Tableau",
        "Real Estate Data",
        "Web Scraping"
    ]

    MAX_PAGES = 5

    db = SessionLocal()
    storage = PostgresStorage(db)
    parser = UpworkParser()

    try:
        for kw in keywords:
            logger.info(f"\nğŸ” === å¼€å§‹æœç´¢ä»»åŠ¡: {kw} ===")

            # ğŸŸ¢ ç­–ç•¥è°ƒæ•´ï¼šæ¯ä¸ªå…³é”®è¯å¯åŠ¨ä¸€ä¸ªæ–°çš„æµè§ˆå™¨å®ä¾‹
            # é˜²æ­¢é•¿æ—¶é—´è¿è¡Œå¯¼è‡´çš„æŒ‡çº¹ç§¯ç´¯æˆ–å†…å­˜æ³„æ¼
            browser = StealthBrowserFetcher(headless=False)

            try:
                for page in range(1, MAX_PAGES + 1):
                    logger.info(f"   ğŸ“„ æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µ...")

                    encoded_kw = urllib.parse.quote(kw)
                    url = f"https://www.upwork.com/nx/search/jobs/?q={encoded_kw}&sort=recency&page={page}"

                    # --- é‡è¯•å¾ªç¯ ---
                    html = None
                    for attempt in range(3):
                        try:
                            html = browser.fetch(url, wait_for_selector="article", sleep_time=10)
                            if html: break
                        except Exception as e:
                            logger.warning(f"      âš ï¸ æŠ“å–å¼‚å¸¸ (å°è¯• {attempt + 1}/3): {e}")
                            # å¦‚æœæµè§ˆå™¨å´©äº†ï¼Œè¿™é‡Œå…¶å®åº”è¯¥é‡å¯æµè§ˆå™¨ï¼Œç®€ä¾¿èµ·è§å…ˆåªåšå»¶æ—¶
                            time.sleep(5)

                    if html:
                        df = parser.parse(html)

                        if not df.empty:
                            logger.info(f"      âœ… æˆåŠŸè§£æ {len(df)} ä¸ªèŒä½")

                            # æ•°æ®è¡¥å…¨
                            if 'skills' not in df.columns:
                                df['skills'] = ""
                            df['search_keyword'] = kw
                            df['skills'] = df['skills'].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x))

                            # å…¥åº“
                            count = 0
                            for _, row in df.iterrows():
                                if not row['url']: continue
                                exists = storage.get(UpworkJob, row['url'])
                                if not exists:
                                    job = UpworkJob(
                                        url=row['url'],
                                        title=row['title'],
                                        job_type=row['job_type'],
                                        budget_min=row['budget_min'],
                                        budget_max=row['budget_max'],
                                        posted_time=row['posted_time'],
                                        search_keyword=row['search_keyword'],
                                        description=row['description'],
                                        skills=row['skills']
                                    )
                                    storage.add(job)
                                    count += 1

                            storage.commit()
                            logger.info(f"      ğŸ’¾ æ–°å¢å…¥åº“: {count} æ¡")

                        else:
                            logger.warning(f"      âš ï¸ é¡µé¢å·²åŠ è½½ä½†æœªè§£æåˆ°æ•°æ® (å¯èƒ½ç¿»åˆ°åº•äº†)")
                            # å¦‚æœè¿ç»­ç©ºé¡µï¼Œå¯ä»¥ break (è¿™é‡Œå…ˆä¸ break åªè¦ä¸€é¡µç©º)
                    else:
                        logger.error(f"      âŒ ç¬¬ {page} é¡µæŠ“å–å½»åº•å¤±è´¥")

                    # ç¿»é¡µä¼‘æ¯
                    import random
                    sleep_time = random.randint(10, 15)
                    logger.info(f"      ğŸ˜´ ä¼‘æ¯ {sleep_time} ç§’...")
                    time.sleep(sleep_time)

            except Exception as kw_err:
                logger.error(f"âŒ å…³é”®è¯ {kw} ä»»åŠ¡å‘ç”Ÿè‡´å‘½é”™è¯¯: {kw_err}")

            finally:
                # æ— è®ºè¿™ä¸ªå…³é”®è¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å…³é—­æµè§ˆå™¨ï¼Œæ¸…ç†ç¯å¢ƒ
                browser.close()
                logger.info(f"ğŸ›‘ å·²å…³é—­æµè§ˆå™¨ã€‚å†·å´ 10 ç§’å‡†å¤‡ä¸‹ä¸€ä¸ªå…³é”®è¯...")
                time.sleep(10)

    except Exception as e:
        logger.critical(f"âŒ ä¸»è¿›ç¨‹å´©æºƒ: {e}")
    finally:
        db.close()
        logger.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡ç»“æŸã€‚")


if __name__ == "__main__":
    run()
