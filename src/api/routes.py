from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from src.database import get_db
from src.models import UpworkJob
from typing import List, Optional
from src.api.auth import verify_api_key

# å…¨å±€é‰´æƒ
router = APIRouter(dependencies=[Depends(verify_api_key)])


@router.get("/jobs", tags=["Jobs"])
def get_jobs(
        limit: int = 10,
        keyword: Optional[str] = None,
        db: Session = Depends(get_db)
):
    """
    è·å–èŒä½åˆ—è¡¨ (æ”¯æŒå…³é”®è¯è¿‡æ»¤)
    """
    query = db.query(UpworkJob)

    if keyword:
        query = query.filter(UpworkJob.search_keyword.ilike(f"%{keyword}%"))

    jobs = query.order_by(UpworkJob.created_at.desc()).limit(limit).all()
    return jobs


@router.get("/stats", tags=["Analytics"])
def get_stats(db: Session = Depends(get_db)):
    """
    è·å–ç»Ÿè®¡æ•°æ®
    """
    try:
        total = db.query(UpworkJob).count()
        return {
            "total_jobs": total,
            "status": "healthy",
            "db_connection": "ok"
        }
    except Exception as e:
        return {
            "status": "error",
            "detail": str(e)
        }


def run_crawler_task(keyword: str):
    """
    åå°ä»»åŠ¡é€»è¾‘
    """
    print(f"ğŸš€ [Background] æ”¶åˆ°æŠ“å–è¯·æ±‚: {keyword}")

    try:
        # ğŸŸ¢ å»¶è¿Ÿå¯¼å…¥ (Lazy Import) - å…³é”®ä¿®å¤ï¼
        # åªæœ‰åœ¨çœŸæ­£æ‰§è¡Œä»»åŠ¡æ—¶æ‰åŠ è½½çˆ¬è™«æ¨¡å—ï¼Œé¿å… API å¯åŠ¨æ—¶å› ç¼º Chrome æŠ¥é”™
        from src.jobs import scrape_upwork

        # æ³¨æ„ï¼šç›®å‰çš„ scrape_upwork.run() æ˜¯è·‘æ­»æ•°æ®çš„
        # å¦‚æœä½ æƒ³è®©å®ƒåªè·‘è¿™ä¸ª keywordï¼Œä½ éœ€è¦å»ä¿®æ”¹ scrape_upwork.run æ¥å—å‚æ•°
        # è¿™é‡Œæš‚æ—¶å…ˆè·‘å…¨é‡
        scrape_upwork.run()

    except ImportError as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ— æ³•åŠ è½½çˆ¬è™«æ¨¡å— (å¯èƒ½æ˜¯æœåŠ¡å™¨ç¼ºå°‘ Chrome ç¯å¢ƒ): {e}")
    except Exception as e:
        print(f"âŒ çˆ¬è™«è¿è¡Œå‡ºé”™: {e}")


@router.post("/crawl", tags=["Actions"])
def trigger_crawl(
        keyword: str,
        background_tasks: BackgroundTasks
):
    """
    è§¦å‘çˆ¬è™«ä»»åŠ¡ (å¼‚æ­¥)
    """
    background_tasks.add_task(run_crawler_task, keyword)

    return {
        "message": f"çˆ¬è™«ä»»åŠ¡å·²æäº¤è‡³åå°é˜Ÿåˆ—: {keyword}",
        "status": "processing",
        "note": "å¦‚æœæ˜¯äº‘ç«¯ç¯å¢ƒä¸”æœªé…ç½® Chromeï¼Œæ­¤ä»»åŠ¡å¯èƒ½ä¼šå¤±è´¥ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—ã€‚"
    }
